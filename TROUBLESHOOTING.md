# ARC_Spec_Python æ•…éšœæ’é™¤æŒ‡å—

æœ¬æŒ‡å—å¸®åŠ©æ‚¨è§£å†³åœ¨ä½¿ç”¨ARC_Spec_Pythonæ—¶å¯èƒ½é‡åˆ°çš„å¸¸è§é—®é¢˜ã€‚

## ğŸ“‹ ç›®å½•

- [å®‰è£…é—®é¢˜](#å®‰è£…é—®é¢˜)
- [é…ç½®é—®é¢˜](#é…ç½®é—®é¢˜)
- [è§£æå™¨é—®é¢˜](#è§£æå™¨é—®é¢˜)
- [è¿è¡Œæ—¶é”™è¯¯](#è¿è¡Œæ—¶é”™è¯¯)
- [æ€§èƒ½é—®é¢˜](#æ€§èƒ½é—®é¢˜)
- [é›†æˆé—®é¢˜](#é›†æˆé—®é¢˜)
- [è°ƒè¯•æŠ€å·§](#è°ƒè¯•æŠ€å·§)
- [å¸¸è§é”™è¯¯ä»£ç ](#å¸¸è§é”™è¯¯ä»£ç )
- [è·å–å¸®åŠ©](#è·å–å¸®åŠ©)

## ğŸ”§ å®‰è£…é—®é¢˜

### é—®é¢˜1: å¯¼å…¥æ¨¡å—å¤±è´¥

**é”™è¯¯ä¿¡æ¯:**
```
ImportError: No module named 'arcspec_ai'
ModuleNotFoundError: No module named 'arcspec_ai.configurator'
```

**å¯èƒ½åŸå› :**
- é¡¹ç›®è·¯å¾„æœªæ·»åŠ åˆ°Pythonè·¯å¾„
- é¡¹ç›®ç»“æ„ä¸å®Œæ•´
- Pythonç¯å¢ƒé—®é¢˜

**è§£å†³æ–¹æ¡ˆ:**

1. **æ£€æŸ¥é¡¹ç›®ç»“æ„:**
   ```bash
   ls -la
   # åº”è¯¥çœ‹åˆ° arcspec_ai/ ç›®å½•
   ls -la arcspec_ai/
   # åº”è¯¥çœ‹åˆ° configurator/ ç›®å½•
   ```

2. **æ·»åŠ é¡¹ç›®è·¯å¾„:**
   ```python
   import sys
   from pathlib import Path
   
   # æ–¹æ³•1: ç›¸å¯¹è·¯å¾„
   project_root = Path(__file__).parent.parent
   sys.path.insert(0, str(project_root))
   
   # æ–¹æ³•2: ç»å¯¹è·¯å¾„
   sys.path.insert(0, '/path/to/ARC_Spec_Python')
   
   # ç„¶åå¯¼å…¥
   from arcspec_ai.configurator import load_ai_configs
   ```

3. **æ£€æŸ¥Pythonç¯å¢ƒ:**
   ```bash
   python --version
   which python
   pip list
   ```

### é—®é¢˜2: ä¾èµ–åº“ç¼ºå¤±

**é”™è¯¯ä¿¡æ¯:**
```
ModuleNotFoundError: No module named 'requests'
ModuleNotFoundError: No module named 'openai'
```

**è§£å†³æ–¹æ¡ˆ:**

1. **å®‰è£…åŸºç¡€ä¾èµ–:**
   ```bash
   pip install requests openai anthropic google-generativeai
   ```

2. **ä½¿ç”¨requirements.txt:**
   ```bash
   pip install -r requirements.txt
   ```

3. **æ£€æŸ¥è™šæ‹Ÿç¯å¢ƒ:**
   ```bash
   # æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
   source venv/bin/activate  # Linux/Mac
   venv\Scripts\activate     # Windows
   
   # ç„¶åå®‰è£…ä¾èµ–
   pip install -r requirements.txt
   ```

## âš™ï¸ é…ç½®é—®é¢˜

### é—®é¢˜1: æœªæ‰¾åˆ°é…ç½®æ–‡ä»¶

**é”™è¯¯ä¿¡æ¯:**
```
æœªæ‰¾åˆ°ä»»ä½•é…ç½®æ–‡ä»¶
No configuration files found in directory
```

**è§£å†³æ–¹æ¡ˆ:**

1. **æ£€æŸ¥é…ç½®ç›®å½•:**
   ```bash
   ls -la configs/
   # åº”è¯¥çœ‹åˆ° .ai.json æ–‡ä»¶
   ```

2. **æ£€æŸ¥æ–‡ä»¶æ‰©å±•å:**
   ```bash
   # æ­£ç¡®çš„æ–‡ä»¶åæ ¼å¼
   mycustom.ai.json
   openai_gpt4.ai.json
   
   # é”™è¯¯çš„æ ¼å¼
   mycustom.json
   config.ai.txt
   ```

3. **åˆ›å»ºç¤ºä¾‹é…ç½®:**
   ```json
   {
     "FriendlyName": "æˆ‘çš„è‡ªå®šä¹‰é…ç½®",
     "Model": "gpt-3.5-turbo",
     "ResponseType": "OpenAI",
     "Description": "åŸºäºOpenAIçš„èŠå¤©é…ç½®",
     "Parameters": {
       "api_key": "your-api-key-here",
       "base_url": "https://api.openai.com/v1",
       "max_tokens": 1000,
       "temperature": 0.7
     }
   }
   ```

### é—®é¢˜2: é…ç½®æ–‡ä»¶æ ¼å¼é”™è¯¯

**é”™è¯¯ä¿¡æ¯:**
```
JSON decode error
é…ç½®éªŒè¯å¤±è´¥
Invalid configuration format
```

**è§£å†³æ–¹æ¡ˆ:**

1. **éªŒè¯JSONæ ¼å¼:**
   ```bash
   # ä½¿ç”¨åœ¨çº¿JSONéªŒè¯å™¨æˆ–å‘½ä»¤è¡Œå·¥å…·
   python -m json.tool configs/mycustom.ai.json
   ```

2. **æ£€æŸ¥å¿…éœ€å­—æ®µ:**
   ```json
   {
     "FriendlyName": "å¿…éœ€å­—æ®µ",
     "Model": "å¿…éœ€å­—æ®µ",
     "ResponseType": "å¿…éœ€å­—æ®µ",
     "Parameters": {
       "api_key": "å¿…éœ€å­—æ®µ"
     }
   }
   ```

3. **å¸¸è§æ ¼å¼é”™è¯¯:**
   ```json
   // é”™è¯¯: å°¾éšé€—å·
   {
     "Model": "gpt-3.5-turbo",
   }
   
   // é”™è¯¯: å•å¼•å·
   {
     'Model': 'gpt-3.5-turbo'
   }
   
   // æ­£ç¡®æ ¼å¼
   {
     "Model": "gpt-3.5-turbo"
   }
   ```

### é—®é¢˜3: APIå¯†é’¥é—®é¢˜

**é”™è¯¯ä¿¡æ¯:**
```
Authentication failed
Invalid API key
API key not found
```

**è§£å†³æ–¹æ¡ˆ:**

1. **æ£€æŸ¥APIå¯†é’¥æ ¼å¼:**
   ```json
   {
     "Parameters": {
       "api_key": "sk-..."  // OpenAIæ ¼å¼
       // æˆ–
       "api_key": "sk-ant-..."  // Anthropicæ ¼å¼
     }
   }
   ```

2. **ä½¿ç”¨ç¯å¢ƒå˜é‡:**
   ```bash
   # è®¾ç½®ç¯å¢ƒå˜é‡
   export OPENAI_API_KEY="your-key-here"
   export ANTHROPIC_API_KEY="your-key-here"
   ```

3. **éªŒè¯APIå¯†é’¥:**
   ```python
   import requests
   
   # æµ‹è¯•OpenAI API
   headers = {"Authorization": f"Bearer {api_key}"}
   response = requests.get(
       "https://api.openai.com/v1/models", 
       headers=headers
   )
   print(response.status_code)
   ```

## ğŸ” è§£æå™¨é—®é¢˜

### é—®é¢˜1: è§£æå™¨æœªæ‰¾åˆ°

**é”™è¯¯ä¿¡æ¯:**
```
è§£æå™¨ 'OpenAI' ä¸å¯ç”¨
Parser not found for ResponseType
```

**è§£å†³æ–¹æ¡ˆ:**

1. **æ£€æŸ¥è§£æå™¨ç›®å½•:**
   ```bash
   ls -la arcspec_ai/parsers/
   # åº”è¯¥çœ‹åˆ°å¯¹åº”çš„è§£æå™¨æ–‡ä»¶
   ```

2. **æ£€æŸ¥è§£æå™¨æ³¨å†Œ:**
   ```python
   from arcspec_ai.configurator import load_parsers
   
   parser_registry = load_parsers('./arcspec_ai/parsers')
   print("å¯ç”¨è§£æå™¨:", parser_registry.list_parsers())
   ```

3. **æ£€æŸ¥ResponseTypeåŒ¹é…:**
   ```json
   // é…ç½®æ–‡ä»¶ä¸­çš„ResponseTypeå¿…é¡»ä¸è§£æå™¨ç±»ååŒ¹é…
   {
     "ResponseType": "OpenAI"  // å¿…é¡»æœ‰å¯¹åº”çš„OpenAIè§£æå™¨ç±»
   }
   ```

### é—®é¢˜2: è§£æå™¨åˆå§‹åŒ–å¤±è´¥

**é”™è¯¯ä¿¡æ¯:**
```
è§£æå™¨åˆå§‹åŒ–å¤±è´¥
Parser initialization error
```

**è§£å†³æ–¹æ¡ˆ:**

1. **æ£€æŸ¥è§£æå™¨å®ç°:**
   ```python
   # ç¡®ä¿è§£æå™¨ç»§æ‰¿è‡ªBaseParser
   from arcspec_ai.parsers.base_parser import BaseParser
   
   class MyParser(BaseParser):
       def __init__(self, config):
           super().__init__(config)
           # åˆå§‹åŒ–é€»è¾‘
   ```

2. **æ£€æŸ¥é…ç½®å‚æ•°:**
   ```python
   # ç¡®ä¿æ‰€éœ€å‚æ•°éƒ½åœ¨é…ç½®ä¸­
   required_params = ['api_key', 'model']
   for param in required_params:
       if param not in config.get('Parameters', {}):
           raise ValueError(f"ç¼ºå°‘å¿…éœ€å‚æ•°: {param}")
   ```

## ğŸš¨ è¿è¡Œæ—¶é”™è¯¯

### é—®é¢˜1: ç½‘ç»œè¿æ¥é”™è¯¯

**é”™è¯¯ä¿¡æ¯:**
```
ConnectionError: Failed to establish connection
Timeout error
SSL certificate verify failed
```

**è§£å†³æ–¹æ¡ˆ:**

1. **æ£€æŸ¥ç½‘ç»œè¿æ¥:**
   ```bash
   ping api.openai.com
   curl -I https://api.openai.com/v1/models
   ```

2. **é…ç½®ä»£ç†:**
   ```python
   import os
   
   # è®¾ç½®ä»£ç†
   os.environ['HTTP_PROXY'] = 'http://proxy.company.com:8080'
   os.environ['HTTPS_PROXY'] = 'https://proxy.company.com:8080'
   ```

3. **SSLé—®é¢˜:**
   ```python
   import ssl
   import requests
   
   # ä¸´æ—¶ç¦ç”¨SSLéªŒè¯ï¼ˆä¸æ¨èç”¨äºç”Ÿäº§ç¯å¢ƒï¼‰
   requests.packages.urllib3.disable_warnings()
   session = requests.Session()
   session.verify = False
   ```

### é—®é¢˜2: å†…å­˜ä¸è¶³

**é”™è¯¯ä¿¡æ¯:**
```
MemoryError
Out of memory
```

**è§£å†³æ–¹æ¡ˆ:**

1. **å‡å°‘å¹¶å‘æ•°:**
   ```python
   # å‡å°‘çº¿ç¨‹æ± å¤§å°
   with ThreadPoolExecutor(max_workers=2) as executor:
       # å¤„ç†ä»»åŠ¡
   ```

2. **æ‰¹é‡å¤„ç†:**
   ```python
   # åˆ†æ‰¹å¤„ç†å¤§é‡æ•°æ®
   batch_size = 10
   for i in range(0, len(data), batch_size):
       batch = data[i:i+batch_size]
       process_batch(batch)
   ```

3. **æ¸…ç†èµ„æº:**
   ```python
   import gc
   
   # æ‰‹åŠ¨åƒåœ¾å›æ”¶
   gc.collect()
   ```

### é—®é¢˜3: ç¼–ç é—®é¢˜

**é”™è¯¯ä¿¡æ¯:**
```
UnicodeDecodeError
UnicodeEncodeError
```

**è§£å†³æ–¹æ¡ˆ:**

1. **æŒ‡å®šç¼–ç :**
   ```python
   # è¯»å–æ–‡ä»¶æ—¶æŒ‡å®šç¼–ç 
   with open('file.txt', 'r', encoding='utf-8') as f:
       content = f.read()
   
   # å†™å…¥æ–‡ä»¶æ—¶æŒ‡å®šç¼–ç 
   with open('output.txt', 'w', encoding='utf-8') as f:
       f.write(content)
   ```

2. **å¤„ç†ç¼–ç é”™è¯¯:**
   ```python
   # å¿½ç•¥ç¼–ç é”™è¯¯
   text = text.encode('utf-8', errors='ignore').decode('utf-8')
   
   # æ›¿æ¢ç¼–ç é”™è¯¯
   text = text.encode('utf-8', errors='replace').decode('utf-8')
   ```

## âš¡ æ€§èƒ½é—®é¢˜

### é—®é¢˜1: å“åº”é€Ÿåº¦æ…¢

**å¯èƒ½åŸå› :**
- ç½‘ç»œå»¶è¿Ÿ
- APIé™åˆ¶
- é…ç½®ä¸å½“

**è§£å†³æ–¹æ¡ˆ:**

1. **ä¼˜åŒ–é…ç½®:**
   ```json
   {
     "Parameters": {
       "max_tokens": 500,     // å‡å°‘tokenæ•°é‡
       "temperature": 0.3,    // é™ä½éšæœºæ€§
       "timeout": 30          // è®¾ç½®è¶…æ—¶
     }
   }
   ```

2. **ä½¿ç”¨ç¼“å­˜:**
   ```python
   from functools import lru_cache
   
   @lru_cache(maxsize=100)
   def cached_parse(message):
       return parser.parse(message)
   ```

3. **å¹¶å‘å¤„ç†:**
   ```python
   import asyncio
   
   async def process_concurrent(messages):
       tasks = [process_message(msg) for msg in messages]
       results = await asyncio.gather(*tasks)
       return results
   ```

### é—®é¢˜2: å†…å­˜ä½¿ç”¨è¿‡é«˜

**è§£å†³æ–¹æ¡ˆ:**

1. **ç›‘æ§å†…å­˜ä½¿ç”¨:**
   ```python
   import psutil
   import os
   
   process = psutil.Process(os.getpid())
   memory_usage = process.memory_info().rss / 1024 / 1024  # MB
   print(f"å†…å­˜ä½¿ç”¨: {memory_usage:.2f} MB")
   ```

2. **ä¼˜åŒ–æ•°æ®ç»“æ„:**
   ```python
   # ä½¿ç”¨ç”Ÿæˆå™¨è€Œä¸æ˜¯åˆ—è¡¨
   def process_large_file(filename):
       with open(filename, 'r') as f:
           for line in f:  # é€è¡Œå¤„ç†ï¼Œä¸åŠ è½½æ•´ä¸ªæ–‡ä»¶
               yield process_line(line)
   ```

## ğŸ”— é›†æˆé—®é¢˜

### é—®é¢˜1: Flaské›†æˆé—®é¢˜

**é”™è¯¯ä¿¡æ¯:**
```
RuntimeError: Working outside of application context
```

**è§£å†³æ–¹æ¡ˆ:**

```python
from flask import Flask, g

app = Flask(__name__)

# åœ¨åº”ç”¨ä¸Šä¸‹æ–‡ä¸­åˆå§‹åŒ–
with app.app_context():
    g.ai_backend = initialize_ai_backend()

@app.route('/chat', methods=['POST'])
def chat():
    # ä½¿ç”¨åº”ç”¨ä¸Šä¸‹æ–‡ä¸­çš„åç«¯
    backend = g.get('ai_backend')
    if not backend:
        backend = initialize_ai_backend()
        g.ai_backend = backend
    
    return backend.process(request.json['message'])
```

### é—®é¢˜2: å¼‚æ­¥é›†æˆé—®é¢˜

**é”™è¯¯ä¿¡æ¯:**
```
RuntimeError: This event loop is already running
```

**è§£å†³æ–¹æ¡ˆ:**

```python
import asyncio
import nest_asyncio

# å…è®¸åµŒå¥—äº‹ä»¶å¾ªç¯
nest_asyncio.apply()

# æˆ–è€…ä½¿ç”¨çº¿ç¨‹æ± 
from concurrent.futures import ThreadPoolExecutor

async def async_parse(message, parser):
    loop = asyncio.get_event_loop()
    result = await loop.run_in_executor(
        None, parser.parse, message
    )
    return result
```

## ğŸ› è°ƒè¯•æŠ€å·§

### 1. å¯ç”¨è¯¦ç»†æ—¥å¿—

```python
import logging

# è®¾ç½®æ—¥å¿—çº§åˆ«
logging.basicConfig(
    level=logging.DEBUG,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)

# ä¸ºç‰¹å®šæ¨¡å—è®¾ç½®æ—¥å¿—çº§åˆ«
logging.getLogger('arcspec_ai').setLevel(logging.DEBUG)
logging.getLogger('requests').setLevel(logging.WARNING)
```

### 2. ä½¿ç”¨è°ƒè¯•æ¨¡å¼

```python
# åœ¨ä»£ç ä¸­æ·»åŠ è°ƒè¯•ä¿¡æ¯
def debug_config_loading():
    print("=== è°ƒè¯•ä¿¡æ¯ ===")
    print(f"å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}")
    print(f"Pythonè·¯å¾„: {sys.path}")
    print(f"é…ç½®ç›®å½•: {config_dir}")
    print(f"é…ç½®æ–‡ä»¶: {list(Path(config_dir).glob('*.ai.json'))}")
    print("===============")

debug_config_loading()
```

### 3. å•æ­¥æµ‹è¯•

```python
# åˆ†æ­¥æµ‹è¯•æ¯ä¸ªç»„ä»¶
def test_components():
    # 1. æµ‹è¯•é…ç½®åŠ è½½
    try:
        configs = load_ai_configs('./configs')
        print(f"âœ“ é…ç½®åŠ è½½æˆåŠŸ: {len(configs)} ä¸ªé…ç½®")
    except Exception as e:
        print(f"âœ— é…ç½®åŠ è½½å¤±è´¥: {e}")
        return
    
    # 2. æµ‹è¯•è§£æå™¨åŠ è½½
    try:
        parser_registry = load_parsers('./arcspec_ai/parsers')
        print(f"âœ“ è§£æå™¨åŠ è½½æˆåŠŸ: {parser_registry.list_parsers()}")
    except Exception as e:
        print(f"âœ— è§£æå™¨åŠ è½½å¤±è´¥: {e}")
        return
    
    # 3. æµ‹è¯•è§£æå™¨åˆ›å»º
    for config_name, config in configs.items():
        try:
            parser = parser_registry.create_parser(
                config['ResponseType'], config
            )
            print(f"âœ“ è§£æå™¨ {config_name} åˆ›å»ºæˆåŠŸ")
        except Exception as e:
            print(f"âœ— è§£æå™¨ {config_name} åˆ›å»ºå¤±è´¥: {e}")

test_components()
```

### 4. æ€§èƒ½åˆ†æ

```python
import time
import cProfile

# ç®€å•è®¡æ—¶
start_time = time.time()
result = parser.parse(message)
end_time = time.time()
print(f"å¤„ç†æ—¶é—´: {end_time - start_time:.2f}s")

# è¯¦ç»†æ€§èƒ½åˆ†æ
def profile_parsing():
    profiler = cProfile.Profile()
    profiler.enable()
    
    result = parser.parse(message)
    
    profiler.disable()
    profiler.print_stats(sort='cumulative')

profile_parsing()
```

## ğŸ“Š å¸¸è§é”™è¯¯ä»£ç 

| é”™è¯¯ä»£ç  | æè¿° | è§£å†³æ–¹æ¡ˆ |
|---------|------|----------|
| CONFIG_001 | é…ç½®æ–‡ä»¶æœªæ‰¾åˆ° | æ£€æŸ¥é…ç½®ç›®å½•å’Œæ–‡ä»¶å |
| CONFIG_002 | é…ç½®æ ¼å¼é”™è¯¯ | éªŒè¯JSONæ ¼å¼ |
| CONFIG_003 | å¿…éœ€å­—æ®µç¼ºå¤± | æ·»åŠ å¿…éœ€çš„é…ç½®å­—æ®µ |
| PARSER_001 | è§£æå™¨æœªæ‰¾åˆ° | æ£€æŸ¥ResponseTypeå’Œè§£æå™¨å®ç° |
| PARSER_002 | è§£æå™¨åˆå§‹åŒ–å¤±è´¥ | æ£€æŸ¥é…ç½®å‚æ•°å’Œä¾èµ– |
| API_001 | APIå¯†é’¥æ— æ•ˆ | éªŒè¯APIå¯†é’¥æ ¼å¼å’Œæƒé™ |
| API_002 | ç½‘ç»œè¿æ¥å¤±è´¥ | æ£€æŸ¥ç½‘ç»œå’Œä»£ç†è®¾ç½® |
| API_003 | è¯·æ±‚è¶…æ—¶ | å¢åŠ è¶…æ—¶æ—¶é—´æˆ–ä¼˜åŒ–è¯·æ±‚ |
| RUNTIME_001 | å†…å­˜ä¸è¶³ | å‡å°‘å¹¶å‘æ•°æˆ–ä¼˜åŒ–å†…å­˜ä½¿ç”¨ |
| RUNTIME_002 | ç¼–ç é”™è¯¯ | æŒ‡å®šæ­£ç¡®çš„æ–‡ä»¶ç¼–ç  |

## ğŸ†˜ è·å–å¸®åŠ©

### 1. æ£€æŸ¥æ—¥å¿—

é¦–å…ˆæŸ¥çœ‹è¯¦ç»†çš„é”™è¯¯æ—¥å¿—ï¼š

```python
import logging

# å¯ç”¨è¯¦ç»†æ—¥å¿—
logging.basicConfig(level=logging.DEBUG)

# è¿è¡Œä½ çš„ä»£ç 
# æŸ¥çœ‹è¾“å‡ºçš„è¯¦ç»†ä¿¡æ¯
```

### 2. åˆ›å»ºæœ€å°å¤ç°ç¤ºä¾‹

åˆ›å»ºä¸€ä¸ªæœ€ç®€å•çš„ç¤ºä¾‹æ¥å¤ç°é—®é¢˜ï¼š

```python
#!/usr/bin/env python3
# minimal_example.py

import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®è·¯å¾„
project_root = Path(__file__).parent
sys.path.insert(0, str(project_root))

try:
    from arcspec_ai.configurator import load_ai_configs, load_parsers
    
    # åŠ è½½é…ç½®
    configs = load_ai_configs('./configs')
    print(f"åŠ è½½çš„é…ç½®: {list(configs.keys())}")
    
    # åŠ è½½è§£æå™¨
    parser_registry = load_parsers('./arcspec_ai/parsers')
    print(f"å¯ç”¨è§£æå™¨: {parser_registry.list_parsers()}")
    
    # æµ‹è¯•è§£æ
    if configs:
        config_name = list(configs.keys())[0]
        config = configs[config_name]
        parser = parser_registry.create_parser(
            config['ResponseType'], config
        )
        result = parser.parse("Hello, world!")
        print(f"è§£æç»“æœ: {result}")
    
except Exception as e:
    import traceback
    print(f"é”™è¯¯: {e}")
    print("è¯¦ç»†é”™è¯¯ä¿¡æ¯:")
    traceback.print_exc()
```

### 3. æ”¶é›†ç³»ç»Ÿä¿¡æ¯

```python
#!/usr/bin/env python3
# system_info.py

import sys
import os
import platform
from pathlib import Path

print("=== ç³»ç»Ÿä¿¡æ¯ ===")
print(f"æ“ä½œç³»ç»Ÿ: {platform.system()} {platform.release()}")
print(f"Pythonç‰ˆæœ¬: {sys.version}")
print(f"å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}")
print(f"Pythonè·¯å¾„: {sys.path[:3]}...")  # åªæ˜¾ç¤ºå‰3ä¸ªè·¯å¾„

print("\n=== é¡¹ç›®ç»“æ„ ===")
project_root = Path('.')
for item in project_root.iterdir():
    if item.is_dir():
        print(f"ğŸ“ {item.name}/")
    else:
        print(f"ğŸ“„ {item.name}")

print("\n=== é…ç½®æ–‡ä»¶ ===")
config_dir = project_root / 'configs'
if config_dir.exists():
    for config_file in config_dir.glob('*.ai.json'):
        print(f"ğŸ“„ {config_file.name}")
else:
    print("âŒ é…ç½®ç›®å½•ä¸å­˜åœ¨")

print("\n=== è§£æå™¨æ–‡ä»¶ ===")
parser_dir = project_root / 'arcspec_ai' / 'parsers'
if parser_dir.exists():
    for parser_file in parser_dir.glob('*.py'):
        if parser_file.name != '__init__.py':
            print(f"ğŸ“„ {parser_file.name}")
else:
    print("âŒ è§£æå™¨ç›®å½•ä¸å­˜åœ¨")

print("\n=== å·²å®‰è£…çš„åŒ… ===")
try:
    import pkg_resources
    installed_packages = [d.project_name for d in pkg_resources.working_set]
    relevant_packages = [p for p in installed_packages if any(
        keyword in p.lower() for keyword in ['openai', 'anthropic', 'google', 'requests']
    )]
    for package in relevant_packages:
        print(f"ğŸ“¦ {package}")
except:
    print("æ— æ³•è·å–åŒ…ä¿¡æ¯")
```

### 4. ç¤¾åŒºæ”¯æŒ

- **GitHub Issues**: åœ¨é¡¹ç›®ä»“åº“ä¸­åˆ›å»ºissue
- **æ–‡æ¡£**: æŸ¥çœ‹é¡¹ç›®æ–‡æ¡£å’ŒAPIå‚è€ƒ
- **ç¤ºä¾‹ä»£ç **: å‚è€ƒexamplesç›®å½•ä¸­çš„ç¤ºä¾‹

### 5. æŠ¥å‘ŠBugæ—¶è¯·åŒ…å«

1. **é”™è¯¯æè¿°**: è¯¦ç»†æè¿°é—®é¢˜
2. **å¤ç°æ­¥éª¤**: å¦‚ä½•é‡ç°é—®é¢˜
3. **æœŸæœ›è¡Œä¸º**: æœŸæœ›çš„æ­£ç¡®è¡Œä¸º
4. **å®é™…è¡Œä¸º**: å®é™…å‘ç”Ÿçš„æƒ…å†µ
5. **ç¯å¢ƒä¿¡æ¯**: ç³»ç»Ÿä¿¡æ¯è„šæœ¬çš„è¾“å‡º
6. **æœ€å°ç¤ºä¾‹**: èƒ½å¤ç°é—®é¢˜çš„æœ€å°ä»£ç 
7. **é”™è¯¯æ—¥å¿—**: å®Œæ•´çš„é”™è¯¯å †æ ˆä¿¡æ¯

---

**è®°ä½**: å¤§å¤šæ•°é—®é¢˜éƒ½å¯ä»¥é€šè¿‡ä»”ç»†æ£€æŸ¥é…ç½®æ–‡ä»¶ã€ç¡®ä¿ä¾èµ–æ­£ç¡®å®‰è£…ã€ä»¥åŠå¯ç”¨è¯¦ç»†æ—¥å¿—æ¥è§£å†³ã€‚å¦‚æœé—®é¢˜ä»ç„¶å­˜åœ¨ï¼Œä¸è¦çŠ¹è±«å¯»æ±‚å¸®åŠ©ï¼